{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!fusermount -u drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "# Replace 'your_dataset.zip' with the actual filename\n",
        "train_tar_path = '/content/drive/MyDrive/ImageNet Dataset/train.tar'\n",
        "val_tar_path = '/content/drive/MyDrive/ImageNet Dataset/val.tar'\n",
        "\n",
        "# Directory to extract the datasets\n",
        "extract_dir = '/content/dataset/'\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "import tarfile\n",
        "\n",
        "# Function to extract tar files\n",
        "def extract_tar(file_path, dest_path):\n",
        "    with tarfile.open(file_path, 'r') as tar_ref:\n",
        "        tar_ref.extractall(dest_path)\n",
        "\n",
        "# Extract training and validation datasets\n",
        "extract_tar(train_tar_path, extract_dir)\n",
        "extract_tar(val_tar_path, extract_dir)\n",
        "\n",
        "# List the contents of the extracted directories\n",
        "print(\"Extracted files:\")\n",
        "print(os.listdir(extract_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXRel-6Efprt",
        "outputId": "ea66106e-cef6-4150-d1f4-de009df5c4f5"
      },
      "id": "BXRel-6Efprt",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Extracted files:\n",
            "['val', 'train']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define paths to the extracted datasets\n",
        "train_dir = os.path.join(extract_dir, 'train')\n",
        "val_dir = os.path.join(extract_dir, 'val')\n",
        "\n",
        "# Image data generator with normalization\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# Training data generator\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Validation data generator\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "id": "m4rZlZS_nbVG",
        "outputId": "6c970274-d156-4c1e-945b-3a57a69038ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "m4rZlZS_nbVG",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load pre-trained MobileNet without the top layer\n",
        "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "6GAoZV6boFoO",
        "outputId": "ab809fd7-3828-45e5-a568-8b9abb8f8426",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6GAoZV6boFoO",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "\u001b[1m17225924/17225924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set training parameters\n",
        "epochs = 10\n",
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "validation_steps = validation_generator.samples // validation_generator.batch_size\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_steps\n",
        ")\n"
      ],
      "metadata": {
        "id": "2tXPmuJ4oOOm",
        "outputId": "2bb5e3c9-2381-47bd-a360-c9eab6a9abfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2tXPmuJ4oOOm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m 463/3125\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m59:55\u001b[0m 1s/step - accuracy: 0.1176 - loss: 4.3842"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on validation data\n",
        "loss, accuracy = model.evaluate(validation_generator, steps=validation_steps)\n",
        "print(f'Validation Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "64tHGvA-oSVF"
      },
      "id": "64tHGvA-oSVF",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}